<!DOCTYPE html>
<html>
<head>
  <meta charset="utf-8">
  
  <meta http-equiv="X-UA-Compatible" content="IE=edge" >
  <title>用逻辑回归分析用户流失问题 | Stanley</title>
  <meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1">
  <meta name="description" content="如果你在运营一个2C的平台，那么你肯定关心用户流失的问题。腾讯有个产品叫信鸽Pro，它能够通过对用户往期行为的挖掘，预测用户潜在的流失（付费）行为，进而实现精准营销。据说，腾讯自己的手游就是用这个系统做用户分析的。这个产品也对外提供服务，目前还是免费的。
信鸽Pro获取大量用户数据，提取用户特征，然后通过算法建模，评估出用户可能的行为，即行为预测。算法建模中最基础的一步就是对用户进行分类。这里就介">
<meta property="og:type" content="article">
<meta property="og:title" content="用逻辑回归分析用户流失问题">
<meta property="og:url" content="http://sunmh207.github.io/2016/02/05/lr/index.html">
<meta property="og:site_name" content="Stanley">
<meta property="og:description" content="如果你在运营一个2C的平台，那么你肯定关心用户流失的问题。腾讯有个产品叫信鸽Pro，它能够通过对用户往期行为的挖掘，预测用户潜在的流失（付费）行为，进而实现精准营销。据说，腾讯自己的手游就是用这个系统做用户分析的。这个产品也对外提供服务，目前还是免费的。
信鸽Pro获取大量用户数据，提取用户特征，然后通过算法建模，评估出用户可能的行为，即行为预测。算法建模中最基础的一步就是对用户进行分类。这里就介">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/points_100.png">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/points_101.png">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/sigmoid_formular.gif">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/sigmoid_0.png">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/sigmoid_1.png">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/points_6.png">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/line_formular.gif">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/line_formular_matrix.gif">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/grade_2d_formular.gif">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/grade_2d_plot.png">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/grade_3d_formular.gif">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/gradient_formular.gif">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/points_6_line.gif">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/points_6_linetrace.gif">
<meta property="og:image" content="http://sunmh207.github.io/images/lr/matrix_err.gif">
<meta property="og:updated_time" content="2016-02-08T13:05:39.000Z">
<meta name="twitter:card" content="summary">
<meta name="twitter:title" content="用逻辑回归分析用户流失问题">
<meta name="twitter:description" content="如果你在运营一个2C的平台，那么你肯定关心用户流失的问题。腾讯有个产品叫信鸽Pro，它能够通过对用户往期行为的挖掘，预测用户潜在的流失（付费）行为，进而实现精准营销。据说，腾讯自己的手游就是用这个系统做用户分析的。这个产品也对外提供服务，目前还是免费的。
信鸽Pro获取大量用户数据，提取用户特征，然后通过算法建模，评估出用户可能的行为，即行为预测。算法建模中最基础的一步就是对用户进行分类。这里就介">
  
    <link rel="alternative" href="/atom.xml" title="Stanley" type="application/atom+xml">
  
  
    <link rel="icon" href="/favicon.png">
  
  <link rel="stylesheet" href="/css/style.css" type="text/css">
</head>

<body>
  <div id="container">
    <div class="left-col">
    <div class="overlay"></div>
<div class="intrude-less">
	<header id="header" class="inner">
		<a href="/" class="profilepic">
			
			<img src="/images/avatar.jpeg" class="js-avatar" style="width: 100%;height: 100%;opacity: 1;">
			
		</a>

		<hgroup>
		  <h1 class="header-author"><a href="/">Stanley</a></h1>
		</hgroup>

		

		
			<div class="switch-btn">
				<div class="icon">
					<div class="icon-ctn">
						<div class="icon-wrap icon-house" data-idx="0">
							<div class="birdhouse"></div>
							<div class="birdhouse_holes"></div>
						</div>
						<div class="icon-wrap icon-ribbon hide" data-idx="1">
							<div class="ribbon"></div>
						</div>
						
						
						<div class="icon-wrap icon-me hide" data-idx="3">
							<div class="user"></div>
							<div class="shoulder"></div>
						</div>
						
					</div>
					
				</div>
				<div class="tips-box hide">
					<div class="tips-arrow"></div>
					<ul class="tips-inner">
						<li>菜单</li>
						<li>標籤</li>
						
						
						<li>關於</li>
						
					</ul>
				</div>
			</div>
		

		<div class="switch-area">
			<div class="switch-wrap">
				<section class="switch-part switch-part1">
					<nav class="header-menu">
						<ul>
						
							<li><a href="/">主页</a></li>
				        
							<li><a href="/archives">所有文章</a></li>
				        
						</ul>
					</nav>
					<nav class="header-nav">
						<div class="social">
							
								<a class="github" target="_blank" href="/#" title="github">github</a>
					        
								<a class="weibo" target="_blank" href="/#" title="weibo">weibo</a>
					        
								<a class="rss" target="_blank" href="/#" title="rss">rss</a>
					        
								<a class="zhihu" target="_blank" href="/#" title="zhihu">zhihu</a>
					        
						</div>
					</nav>
				</section>
				
				
				<section class="switch-part switch-part2">
					<div class="widget tagcloud" id="js-tagcloud">
						<a href="/tags/SVD-机器学习-推荐引擎/" style="font-size: 10px;">SVD 机器学习 推荐引擎</a> <a href="/tags/逻辑回归-机器学习/" style="font-size: 20px;">逻辑回归 机器学习</a>
					</div>
				</section>
				
				
				

				
				
				<section class="switch-part switch-part3">
				
					<div id="js-aboutme">把复杂的问题简单化</div>
				</section>
				
			</div>
		</div>
	</header>				
</div>

    </div>
    <div class="mid-col">
      <nav id="mobile-nav">
  	<div class="overlay">
  		<div class="slider-trigger"></div>
  		<h1 class="header-author js-mobile-header hide">Stanley</h1>
  	</div>
	<div class="intrude-less">
		<header id="header" class="inner">
			<div class="profilepic">
			
				<img src="/images/avatar.jpeg" class="js-avatar" style="width: 100%;height: 100%;opacity: 1;">
			
			</div>
			<hgroup>
			  <h1 class="header-author">Stanley</h1>
			</hgroup>
			
			<nav class="header-menu">
				<ul>
				
					<li><a href="/">主页</a></li>
		        
					<li><a href="/archives">所有文章</a></li>
		        
		        <div class="clearfix"></div>
				</ul>
			</nav>
			<nav class="header-nav">
				<div class="social">
					
						<a class="github" target="_blank" href="/#" title="github">github</a>
			        
						<a class="weibo" target="_blank" href="/#" title="weibo">weibo</a>
			        
						<a class="rss" target="_blank" href="/#" title="rss">rss</a>
			        
						<a class="zhihu" target="_blank" href="/#" title="zhihu">zhihu</a>
			        
				</div>
			</nav>
		</header>				
	</div>
</nav>

      <div class="body-wrap"><article id="post-lr" class="article article-type-post" itemscope itemprop="blogPost">
  
    <div class="article-meta">
      <a href="/2016/02/05/lr/" class="article-date">
  	<time datetime="2016-02-05T04:47:18.000Z" itemprop="datePublished">2016-02-05</time>
</a>
    </div>
  
  <div class="article-inner">
    
      <input type="hidden" class="isFancy" />
    
    
      <header class="article-header">
        
  
    <h1 class="article-title" itemprop="name">
      用逻辑回归分析用户流失问题
    </h1>
  

      </header>
      
      <div class="article-info article-info-post">
        
	<div class="article-tag tagcloud">
		<ul class="article-tag-list"><li class="article-tag-list-item"><a class="article-tag-list-link" href="/tags/逻辑回归-机器学习/">逻辑回归 机器学习</a></li></ul>
	</div>

        

        <div class="clearfix"></div>
      </div>
      
    
    <div class="article-entry" itemprop="articleBody">
      
        <p>如果你在运营一个2C的平台，那么你肯定关心用户流失的问题。腾讯有个产品叫信鸽Pro，它能够通过对用户往期行为的挖掘，预测用户潜在的流失（付费）行为，进而实现精准营销。据说，腾讯自己的手游就是用这个系统做用户分析的。这个产品也对外提供服务，目前还是免费的。</p>
<p>信鸽Pro获取大量用户数据，提取用户特征，然后通过算法建模，评估出用户可能的行为，即行为预测。算法建模中最基础的一步就是对用户进行分类。这里就介绍一种常用的分类算法 － 逻辑回归。</p>
<h2 id="u95EE_u9898"><a href="#u95EE_u9898" class="headerlink" title="问题"></a>问题</h2><p>用户数据很复杂，不太适合直接当作算法介绍的案例，还是先从简单的模型开始为好。简单又直观的模型莫过于从平面上找一些点，然后用算法对其进行分类。</p>
<p>假设平面上有一些点，如图所示：<br><img src="/images/lr/points_100.png" alt=""></p>
<p>整个平面上只有两种图形，一种是三角形，另一种是圆形，并且这些点都大致符合一定的规律。<br>问题：如果随意在这个平面新增加一个点, 比如点P(5,19)，那怎知把它归到哪一组更合适？</p>
<h2 id="u601D_u8DEF"><a href="#u601D_u8DEF" class="headerlink" title="思路"></a>思路</h2><p>我们发现，三角形大都位于左上方，而圆形大都位于右下方。我们可以用尺子在图上画一条直线，该直线尽可能的将三角形和圆形分到两边。然后观察新点位于哪一侧。若与三角形在同一侧，则它应该属于三角形；若位于圆形一侧，则应属于圆形。在本例中，坐标P应该属于三角形更合适。<br><img src="/images/lr/points_101.png" alt=""></p>
<p>这个问题似乎很简单。但是，如果三维空间存在类似的问题，答案就没有那么显而易见了。那4维空间呢? 1024维空间呢? 想想都头大！</p>
<p>不过别担心！借助计算机算法，N维空间分类的问题已经很容易解决，逻辑回归就是常用的一种。</p>
<h1 id="u903B_u8F91_u56DE_u5F52"><a href="#u903B_u8F91_u56DE_u5F52" class="headerlink" title="逻辑回归"></a>逻辑回归</h1><p>逻辑回归的核心思想就是通过现有数据，对分类边界线建立回归公式，以此进行分类。</p>
<p>在介绍算法之前，需要先介绍2个基本概念: Sigmoid函数和矩阵。</p>
<h2 id="Sigmoid_u51FD_u6570"><a href="#Sigmoid_u51FD_u6570" class="headerlink" title="Sigmoid函数"></a>Sigmoid函数</h2><p>Sigmoid函数的表达式为：<br><img src="/images/lr/sigmoid_formular.gif" alt=""></p>
<p>在坐标系中的图形为：<br><img src="/images/lr/sigmoid_0.png" alt=""></p>
<p>x&gt;0时，x越大y越接近于1；x&lt;0时，x越小，y越接近于0。如果把坐标拉长，曲线中间就会很“陡”。直观上x的“轻微”变化，都会导致y接近于0或1。</p>
<p><img src="/images/lr/sigmoid_1.png" alt=""></p>
<p>Sigmoid函数的作用是将任意实数转换成0～1的数，而0和1刚好可以用做分类，比如，<strong>用1表示三角形，用0表示圆形 (后文沿用此标识)</strong>。小于0.5的可以划分为0类，大于0.5的划分为1类。（注：Sigmoid是单调增长函数，因而多个数字通过Sigmoid转换后相对位置不变，这是选择该函数的重要原因。）</p>
<h2 id="u77E9_u9635"><a href="#u77E9_u9635" class="headerlink" title="矩阵"></a>矩阵</h2><p>矩阵是线性代数里的一个概念。矩阵运算可以简化方程式的求解问题。比如，下面的几个坐标点和分割线：</p>
<p><img src="/images/lr/points_6.png" alt=""></p>
<p>其中红色三角形坐标分别是(1,2)、(1.5,7)和(2,6)。绿色圆点坐标分别是（1,0）、(2,3)和(2.5,6)。分割线的函数为y=4x-3. 它的形式还可以转换成：3-4x+y=0 。</p>
<p>我们设表达式z = f(x,y) = 3-4x+y</p>
<p>把六个点的坐标代到这个方程式里,有</p>
<p>&lt;表1&gt;</p>
<table>
<thead>
<tr>
<th style="text-align:center">坐标</th>
<th style="text-align:center">公式</th>
<th style="text-align:right">结果(z)</th>
<th>分类</th>
<th>标识</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">(1,2)</td>
<td style="text-align:center">3-4x+y</td>
<td style="text-align:right">1</td>
<td>三角</td>
<td>1</td>
</tr>
<tr>
<td style="text-align:center">(1.5,7)</td>
<td style="text-align:center">3-4x+y</td>
<td style="text-align:right">5</td>
<td>三角</td>
<td>1</td>
</tr>
<tr>
<td style="text-align:center">(2,6)</td>
<td style="text-align:center">3-4x+y</td>
<td style="text-align:right">1</td>
<td>三角</td>
<td>1</td>
</tr>
<tr>
<td style="text-align:center">(1,0)</td>
<td style="text-align:center">3-4x+y</td>
<td style="text-align:right">-1</td>
<td>圆形</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center">(2,3)</td>
<td style="text-align:center">3-4x+y</td>
<td style="text-align:right">-2</td>
<td>圆形</td>
<td>0</td>
</tr>
<tr>
<td style="text-align:center">(2.5,6)</td>
<td style="text-align:center">3-4x+y</td>
<td style="text-align:right">-1</td>
<td>圆形</td>
<td>0</td>
</tr>
</tbody>
</table>
<p><em>(注：标识1表示三角形；标识0表示圆形)</em><br>结果&gt;0的点在分割线上方，是三角形；结果&lt;0的点在分割线下方，是圆形.<br>因为z的范围是无限的，处理起来困难，所以通过Sigmoid函数将其转换到0～1之间。转换后到结果：</p>
<p>&lt;表2&gt;</p>
<table>
<thead>
<tr>
<th style="text-align:center">坐标</th>
<th style="text-align:center">公式</th>
<th style="text-align:right">结果(z)</th>
<th style="text-align:right">Sigmoid(z)</th>
<th>分类</th>
<th>标识</th>
<th style="text-align:right">误差(Sigmoid-标识)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">(1,2)</td>
<td style="text-align:center">3-4x+y</td>
<td style="text-align:right">1</td>
<td style="text-align:right">0.73</td>
<td>三角</td>
<td>1</td>
<td style="text-align:right">-0.27</td>
</tr>
<tr>
<td style="text-align:center">(1.5,7)</td>
<td style="text-align:center">3-4x+y</td>
<td style="text-align:right">5</td>
<td style="text-align:right">0.99</td>
<td>三角</td>
<td>1</td>
<td style="text-align:right">-0.01</td>
</tr>
<tr>
<td style="text-align:center">(2,6)</td>
<td style="text-align:center">3-4x+y</td>
<td style="text-align:right">1</td>
<td style="text-align:right">0.73</td>
<td>三角</td>
<td>1</td>
<td style="text-align:right">-0.27</td>
</tr>
<tr>
<td style="text-align:center">(1,0)</td>
<td style="text-align:center">3-4x+y</td>
<td style="text-align:right">-1</td>
<td style="text-align:right">0.27</td>
<td>圆形</td>
<td>0</td>
<td style="text-align:right">0.27</td>
</tr>
<tr>
<td style="text-align:center">(2,3)</td>
<td style="text-align:center">3-4x+y</td>
<td style="text-align:right">-2</td>
<td style="text-align:right">0.12</td>
<td>圆形</td>
<td>0</td>
<td style="text-align:right">0.12</td>
</tr>
<tr>
<td style="text-align:center">(2.5,6)</td>
<td style="text-align:center">3-4x+y</td>
<td style="text-align:right">-1</td>
<td style="text-align:right">0.27</td>
<td>圆形</td>
<td>0</td>
<td style="text-align:right">0.27</td>
</tr>
</tbody>
</table>
<p>我们发现，Sigmoid值与分类标识很接近,而且越接近也就越符合标识的特征。我们可以用标识值减去Sigmoid值来表示点与分类“吻合”的“误差”程度。误差的绝对值越小，越符合标识特征。比如点(1.5,7)的误差为0.01，说明它属于三角形的可能性非常大。从图上看，它确实在最上方，远离分割线，最具有三角形分类特征（或最不可能被误认为是圆形组）。</p>
<p>我们把分割线表达形式从上面的 z=3-4x+y 转换成以下的标准形式：<br><img src="/images/lr/line_formular.gif" alt=""><br>其中<br>w0x0 是由第一项转换来的，是常数项，因此我们常设x0==1<br>w1x1 是由第二项转换来的，就是把符号x换成了x1<br>w2x2 是由第三项转换来的，就是把符号y换成了x2</p>
<p>这样，我们可以抽取出两个向量:<strong>w</strong>和<strong>x</strong>。其中<strong>w</strong>=[w0,w1,w2],<strong>x</strong>=[1,x1,x2]. <strong>w</strong>是系数向量，<strong>x</strong>是自变量向量。于是得到表达式：<br><img src="/images/lr/line_formular_matrix.gif" alt=""></p>
<p>现在的问题转换成，已知所有的<strong>x</strong>向量，欲使误差（1-Sigmoid(z)）的值达到最小，求向量<strong>w</strong>的值。如果得到了<strong>w</strong>，也就知道了分割线的表达式。</p>
<h2 id="u7528_u68AF_u5EA6_u4E0B_u964D_u6CD5_u6C42w"><a href="#u7528_u68AF_u5EA6_u4E0B_u964D_u6CD5_u6C42w" class="headerlink" title="用梯度下降法求w"></a>用梯度下降法求<strong>w</strong></h2><p>所谓梯度，就是函数在某个点增长最快的方向，有时称为斜度。如果函数是一个曲线，某个点的梯度就是该点的斜率，或导数。<br><img src="/images/lr/grade_2d_formular.gif" alt=""><br><img src="/images/lr/grade_2d_plot.png" alt=""><br>如果是曲面，梯度是在两个方向上求偏导。<br><img src="/images/lr/grade_3d_formular.gif" alt=""></p>
<p>梯度下降法的核心思想是：欲求函数的最小值，先从某一点出发，沿着函数的梯度的反方向探寻，直到找到最小值。设每次探寻Delta(w)，步长为alpha，则梯度下降的算法的公式为：<br><img src="/images/lr/gradient_formular.gif" alt=""></p>
<h2 id="u4EE3_u7801"><a href="#u4EE3_u7801" class="headerlink" title="代码"></a>代码</h2><p>loadData()函数返回坐标值和分类标识。第一个返回值取前三列 x0,x1,x2；第二个返回值取第四列，即label</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding:utf-8</span></span><br><span class="line"><span class="keyword">from</span> numpy <span class="keyword">import</span> *</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">loadData</span><span class="params">()</span>:</span></span><br><span class="line">  data = [[<span class="number">1</span>, <span class="number">1</span>, <span class="number">2</span>, <span class="number">1</span>],</span><br><span class="line">          [<span class="number">1</span>, <span class="number">2</span>, <span class="number">6</span>, <span class="number">1</span>],</span><br><span class="line">          [<span class="number">1</span>, <span class="number">1.5</span>, <span class="number">7</span>, <span class="number">1</span>],</span><br><span class="line">          [<span class="number">1</span>, <span class="number">1</span>, <span class="number">0</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">1</span>, <span class="number">2</span>, <span class="number">3</span>, <span class="number">0</span>],</span><br><span class="line">          [<span class="number">1</span>, <span class="number">2.5</span>, <span class="number">6</span>, <span class="number">0</span>]]</span><br><span class="line">  ds = [e[<span class="number">0</span>:<span class="number">3</span>] <span class="keyword">for</span> e <span class="keyword">in</span> data]</span><br><span class="line">  label = [e[-<span class="number">1</span>] <span class="keyword">for</span> e <span class="keyword">in</span> data]</span><br><span class="line">  <span class="keyword">return</span> ds, label</span><br></pre></td></tr></table></figure>
<p>Sigmoid函数</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sigmoid</span><span class="params">(x)</span>:</span></span><br><span class="line">    <span class="keyword">return</span> <span class="number">1.0</span>/(<span class="number">1</span>+exp(-x))</span><br></pre></td></tr></table></figure>
<p>梯度下降算法<br><strong>input</strong> ds: 坐标数据; label: 标签<br><strong>return</strong>  w: 系数向量, nx1的矩阵  </p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">reduce</span><span class="params">(ds, label)</span>:</span></span><br><span class="line">  <span class="comment">#转换成矩阵</span></span><br><span class="line">  dmat = mat(ds)</span><br><span class="line">  lmat = mat(label).T</span><br><span class="line">  <span class="comment">#mxn的矩阵的行数和列数</span></span><br><span class="line">  m,n = shape(dmat)</span><br><span class="line">  <span class="comment">#步长</span></span><br><span class="line">  alpha = <span class="number">0.1</span></span><br><span class="line">  <span class="comment">#循环次数</span></span><br><span class="line">  loops = <span class="number">200</span></span><br><span class="line">  <span class="comment">#初始化w为[1,1,1],即分割线为 1+x+y=0</span></span><br><span class="line">  w = ones((n,<span class="number">1</span>))</span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(loops): </span><br><span class="line">    h = sigmoid(dmat*w)</span><br><span class="line">    err = (h - lmat)</span><br><span class="line">    w = w - alpha * dmat.T* err </span><br><span class="line">  <span class="keyword">return</span> w.A[:,<span class="number">0</span>]</span><br></pre></td></tr></table></figure>
<p>测试<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">test</span><span class="params">()</span>:</span></span><br><span class="line">  ds,l = loadData()</span><br><span class="line">  <span class="keyword">print</span> reduce(ds,l)</span><br></pre></td></tr></table></figure></p>
<p>运行结果<br><figure class="highlight"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">&#62;&#62;&#62; import lr&#10;&#62;&#62;&#62; lr.test()&#10;[ 3.1007773  -5.54393712  1.60563033]</span><br></pre></td></tr></table></figure></p>
<p>也就是说w=(3.1, -5.5, 1.6), 即w0=3.1, w1=-5.5, w2 = 1.6</p>
<p>分割线的表达式为：w0+w1x+w2y=0， 代入w后得 3.1-5.5x+1.6y=0, 即y=3.44x-1.9 。 见下图，该直线正确地将图形划分开。</p>
<p><img src="/images/lr/points_6_line.gif" alt=""></p>
<h2 id="u8FC7_u7A0B_u5206_u6790"><a href="#u8FC7_u7A0B_u5206_u6790" class="headerlink" title="过程分析"></a>过程分析</h2><p>不需要过程分析，是导数运算，见<br><a href="http://blog.csdn.net/xiazdong/article/details/7950084" target="_blank" rel="external">http://blog.csdn.net/xiazdong/article/details/7950084</a></p>
<p>逻辑回归的核心代码只有几行<br><figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">w = ones((n,<span class="number">1</span>))          <span class="comment">#---1</span></span><br><span class="line">  <span class="keyword">for</span> i <span class="keyword">in</span> range(loops): <span class="comment">#---2</span></span><br><span class="line">    h = sigmoid(dmat*w)  <span class="comment">#---3</span></span><br><span class="line">    err = (h - lmat)     <span class="comment">#---4</span></span><br><span class="line">    w = w - alpha * dmat.T* err <span class="comment">#---5</span></span><br></pre></td></tr></table></figure></p>
<p>第一行，初始化系数向量w=[1,1,1]，也就是初始化分割线为1+x+y=0 (下图0号线)。 然后逐步调整分割线点参数，直到达到最佳值。<br>第二行，进入循环<br>第三行，根据系数向量计算出每一个点的Sigmoid值，相当于表2的Sigmoid(z)这一列；第一次进入循环后，计算出来的值为h=[0.9820,0.9999,0.9998,0.8808,0.9975,0.9999]<br>第四行，计算误差：err=h-lmat;从表中可以看出，三角形的点误差很小，圆形点的误差很大。观察0号线会发现，0号线把三角形准确的划分到了正确位置（误差值小）；但把圆形划分到了错误位置（误差值大）。</p>
<ul>
<li>误差的含义：如果绝对值<0.5,该点划分正确；绝对值>0.5，该点划分错误。符号为正表示分类1，符号为负表示分类0</0.5,该点划分正确；绝对值></li>
</ul>
<p>&lt;表3-1：第一次循环&gt;</p>
<table>
<thead>
<tr>
<th style="text-align:center">坐标(dmat)</th>
<th style="text-align:center">公式(w)</th>
<th style="text-align:right">结果(dmat*w)</th>
<th style="text-align:right">h=Sigmoid(dmat*w)</th>
<th>分类</th>
<th>标识lmat</th>
<th style="text-align:right">误差(err=h-lmat)</th>
</tr>
</thead>
<tbody>
<tr>
<td style="text-align:center">(1,2)</td>
<td style="text-align:center">1+x+y</td>
<td style="text-align:right">4</td>
<td style="text-align:right">0.9820</td>
<td>三角</td>
<td>1</td>
<td style="text-align:right">-0.0180</td>
</tr>
<tr>
<td style="text-align:center">(1.5,7)</td>
<td style="text-align:center">1+x+y</td>
<td style="text-align:right">9.5</td>
<td style="text-align:right">0.9999</td>
<td>三角</td>
<td>1</td>
<td style="text-align:right">-0.0001</td>
</tr>
<tr>
<td style="text-align:center">(2,6)</td>
<td style="text-align:center">1+x+y</td>
<td style="text-align:right">9</td>
<td style="text-align:right">0.9998</td>
<td>三角</td>
<td>1</td>
<td style="text-align:right">-0.0002</td>
</tr>
<tr>
<td style="text-align:center">(1,0)</td>
<td style="text-align:center">1+x+y</td>
<td style="text-align:right">2</td>
<td style="text-align:right">0.8808</td>
<td>圆形</td>
<td>0</td>
<td style="text-align:right">0.8808</td>
</tr>
<tr>
<td style="text-align:center">(2,3)</td>
<td style="text-align:center">1+x+y</td>
<td style="text-align:right">6</td>
<td style="text-align:right">0.9975</td>
<td>圆形</td>
<td>0</td>
<td style="text-align:right">0.9975</td>
</tr>
<tr>
<td style="text-align:center">(2.5,6)</td>
<td style="text-align:center">1+x+y</td>
<td style="text-align:right">9.5</td>
<td style="text-align:right">0.9999</td>
<td>圆形</td>
<td>0</td>
<td style="text-align:right">0.9999</td>
</tr>
</tbody>
</table>
<p>&lt;分割线调整图&gt; 线编号n表示第n次调整(循环)之后的位置<br><img src="/images/lr/points_6_linetrace.gif" alt=""></p>
<p>可以看到，每次循环都会调整分割线的位置，到第200次的时候，分割线已经能够很好对坐标分组了。</p>
<h3 id="u8C03_u6574_u53C2_u6570"><a href="#u8C03_u6574_u53C2_u6570" class="headerlink" title="调整参数"></a>调整参数</h3><p>首先把dmat转置后与误差相乘，dmat.T* err=[-2.86,-5.36,-8.95]<br><img src="/images/lr/matrix_err.gif" alt=""><br>含义是，w0需要向负方向移动2.86个单位 (不要纠结于单位的含义，只需关注数字。数字的目的在于计算需要在3个维度移动的比例而已)；w1需要向负方向移动5.36个单位；w2需要在负方向移动8.95个单位。</p>
<p>每次不能移动太多，所以要乘以一个很小的参数alpha. 然后<strong>w</strong>向量减去这个误差。即</p>
<p>w = w - alpha * dmat.T * err<br>第一次循环后w=[0.71,0.46,0.1]，即分割线被调整为0.71+0.46x+0.1y=0 ， 见上图2号直线。</p>
<h2 id="u5E94_u7528"><a href="#u5E94_u7528" class="headerlink" title="应用"></a>应用</h2><p>把上面的x,y转换成用户特征，比如登录时间，登录频率等等。把三角形和圆形转换成付费用户和免费用户，就得到了付费用户预测模型；把三角形和圆形转换成流失用户和有效用户，就得到了流失用户预测模型。<br>当然，<strong>这只是个理论模型，实际应用要比这复杂的多的多。</strong></p>

      
    </div>
    
  </div>
  
    
<nav id="article-nav">
  
    <a href="/2016/02/08/lr-principle/" id="article-nav-newer" class="article-nav-link-wrap">
      <strong class="article-nav-caption"><</strong>
      <div class="article-nav-title">
        
          用逻辑回归原理
        
      </div>
    </a>
  
  
    <a href="/2016/02/04/LR/" id="article-nav-older" class="article-nav-link-wrap">
      <div class="article-nav-title">用逻辑回归对数据进行分类</div>
      <strong class="article-nav-caption">></strong>
    </a>
  
</nav>

  
</article>


<div class="share_jia">
	<!-- JiaThis Button BEGIN -->
	<div class="jiathis_style">
		<span class="jiathis_txt">分享到: &nbsp; </span>
		<a class="jiathis_button_facebook"></a> 
    <a class="jiathis_button_twitter"></a>
    <a class="jiathis_button_plus"></a> 
    <a class="jiathis_button_tsina"></a>
		<a class="jiathis_button_cqq"></a>
		<a class="jiathis_button_douban"></a>
		<a class="jiathis_button_weixin"></a>
		<a class="jiathis_button_tumblr"></a>
    <a href="http://www.jiathis.com/share" class="jiathis jiathis_txt jtico jtico_jiathis" target="_blank"></a>
	</div>
	<script type="text/javascript" src="http://v3.jiathis.com/code/jia.js?uid=1405949716054953" charset="utf-8"></script>
	<!-- JiaThis Button END -->
</div>






<div class="duoshuo">
	<!-- 多说评论框 start -->
	<div class="ds-thread" data-thread-key="lr" data-title="用逻辑回归分析用户流失问题" data-url="http://sunmh207.github.io/2016/02/05/lr/"></div>
	<!-- 多说评论框 end -->
	<!-- 多说公共JS代码 start (一个网页只需插入一次) -->
	<script type="text/javascript">
	var duoshuoQuery = {short_name:"true"};
	(function() {
		var ds = document.createElement('script');
		ds.type = 'text/javascript';ds.async = true;
		ds.src = (document.location.protocol == 'https:' ? 'https:' : 'http:') + '//static.duoshuo.com/embed.js';
		ds.charset = 'UTF-8';
		(document.getElementsByTagName('head')[0] 
		 || document.getElementsByTagName('body')[0]).appendChild(ds);
	})();
	</script>
	<!-- 多说公共JS代码 end -->
</div>




</div>
      <footer id="footer">
  <div class="outer">
    <div id="footer-info">
    	<div class="footer-left">
    		&copy; 2016 Stanley
    	</div>
      	<div class="footer-right">
      		<a href="http://hexo.io/" target="_blank">Hexo</a>  Theme <a href="https://github.com/litten/hexo-theme-yilia" target="_blank">Yilia</a> by Litten
      	</div>
    </div>
  </div>
</footer>
    </div>
    
  <link rel="stylesheet" href="/fancybox/jquery.fancybox.css" type="text/css">


<script>
	var yiliaConfig = {
		fancybox: true,
		mathjax: true,
		animate: false,
		isHome: false,
		isPost: true,
		isArchive: false,
		isTag: false,
		isCategory: false,
		open_in_new: false
	}
</script>
<script src="http://7.url.cn/edu/jslib/comb/require-2.1.6,jquery-1.9.1.min.js" type="text/javascript"></script>
<script src="/js/main.js" type="text/javascript"></script>



<!-- Google Analytics -->
<script type="text/javascript">
(function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
(i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
})(window,document,'script','//www.google-analytics.com/analytics.js','ga');

ga('create', 'UA-6626015-4', 'auto');
ga('send', 'pageview');

</script>
<!-- End Google Analytics -->




<script type="text/x-mathjax-config">
MathJax.Hub.Config({
    tex2jax: {
        inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
        processEscapes: true,
        skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
    }
});

MathJax.Hub.Queue(function() {
    var all = MathJax.Hub.getAllJax(), i;
    for(i=0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';                 
    }       
});
</script>

<script type="text/javascript" src="http://cdn.mathjax.org/mathjax/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  </div>
</body>
</html>